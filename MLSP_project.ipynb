{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7f56b62-301a-4a14-996a-dce8ee1f832d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: torch in ./env_hf/lib/python3.12/site-packages (2.7.1+computecanada)\n",
      "Requirement already satisfied: filelock in ./env_hf/lib/python3.12/site-packages (from torch) (3.20.0+computecanada)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./env_hf/lib/python3.12/site-packages (from torch) (4.15.0+computecanada)\n",
      "Requirement already satisfied: setuptools in ./env_hf/lib/python3.12/site-packages (from torch) (80.9.0+computecanada)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./env_hf/lib/python3.12/site-packages (from torch) (1.14.0+computecanada)\n",
      "Requirement already satisfied: networkx in ./env_hf/lib/python3.12/site-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./env_hf/lib/python3.12/site-packages (from torch) (3.1.6+computecanada)\n",
      "Requirement already satisfied: fsspec in ./env_hf/lib/python3.12/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0+computecanada)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env_hf/lib/python3.12/site-packages (from jinja2->torch) (3.0.2+computecanada)\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: torchcodec in ./env_hf/lib/python3.12/site-packages (0.7.0+computecanada)\n",
      "Requirement already satisfied: torch~=2.7.0 in ./env_hf/lib/python3.12/site-packages (from torchcodec) (2.7.1+computecanada)\n",
      "Requirement already satisfied: filelock in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (3.20.0+computecanada)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (4.15.0+computecanada)\n",
      "Requirement already satisfied: setuptools in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (80.9.0+computecanada)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (1.14.0+computecanada)\n",
      "Requirement already satisfied: networkx in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (3.1.6+computecanada)\n",
      "Requirement already satisfied: fsspec in ./env_hf/lib/python3.12/site-packages (from torch~=2.7.0->torchcodec) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from sympy>=1.13.3->torch~=2.7.0->torchcodec) (1.3.0+computecanada)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env_hf/lib/python3.12/site-packages (from jinja2->torch~=2.7.0->torchcodec) (3.0.2+computecanada)\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: evaluate in ./env_hf/lib/python3.12/site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in ./env_hf/lib/python3.12/site-packages (from evaluate) (4.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from evaluate) (1.26.4+computecanada)\n",
      "Requirement already satisfied: dill in ./env_hf/lib/python3.12/site-packages (from evaluate) (0.4.0+computecanada)\n",
      "Requirement already satisfied: pandas in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from evaluate) (2.2.1+computecanada)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./env_hf/lib/python3.12/site-packages (from evaluate) (2.32.5+computecanada)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./env_hf/lib/python3.12/site-packages (from evaluate) (4.67.1+computecanada)\n",
      "Requirement already satisfied: xxhash in ./env_hf/lib/python3.12/site-packages (from evaluate) (3.5.0+computecanada)\n",
      "Requirement already satisfied: multiprocess in ./env_hf/lib/python3.12/site-packages (from evaluate) (0.70.18+computecanada)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in ./env_hf/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in ./env_hf/lib/python3.12/site-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from evaluate) (24.1+computecanada)\n",
      "Requirement already satisfied: filelock in ./env_hf/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.20.0+computecanada)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/arrow/21.0.0/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (21.0.0)\n",
      "Requirement already satisfied: httpx<1.0.0 in ./env_hf/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (0.28.1+computecanada)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env_hf/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2+computecanada)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in ./env_hf/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15+computecanada)\n",
      "Requirement already satisfied: anyio in ./env_hf/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.11.0+computecanada)\n",
      "Requirement already satisfied: certifi in ./env_hf/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in ./env_hf/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9+computecanada)\n",
      "Requirement already satisfied: idna in ./env_hf/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.11+computecanada)\n",
      "Requirement already satisfied: h11>=0.16 in ./env_hf/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0+computecanada)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env_hf/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0+computecanada)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./env_hf/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10+computecanada)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1+computecanada)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0+computecanada)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0+computecanada)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0+computecanada)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0+computecanada)\n",
      "Requirement already satisfied: propcache>=0.2.0 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1+computecanada)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in ./env_hf/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0+computecanada)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env_hf/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (3.4.4+computecanada)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env_hf/lib/python3.12/site-packages (from requests>=2.19.0->evaluate) (2.5.0+computecanada)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./env_hf/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets>=2.0.0->evaluate) (1.3.1+computecanada)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from pandas->evaluate) (2.9.0.post0+computecanada)\n",
      "Requirement already satisfied: pytz>=2020.1 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from pandas->evaluate) (2024.1+computecanada)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from pandas->evaluate) (2024.1+computecanada)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0+computecanada)\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: jiwer in ./env_hf/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: click>=8.1.8 in ./env_hf/lib/python3.12/site-packages (from jiwer) (8.3.1)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in ./env_hf/lib/python3.12/site-packages (from jiwer) (3.13.0+computecanada)\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: transformers[torch] in ./env_hf/lib/python3.12/site-packages (4.57.3)\n",
      "Requirement already satisfied: filelock in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (3.20.0+computecanada)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from transformers[torch]) (1.26.4+computecanada)\n",
      "Requirement already satisfied: packaging>=20.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from transformers[torch]) (24.1+computecanada)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (6.0.2+computecanada)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (2024.11.6+computecanada)\n",
      "Requirement already satisfied: requests in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (2.32.5+computecanada)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (0.22.1+computecanada)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (0.5.3+computecanada)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (4.67.1+computecanada)\n",
      "Requirement already satisfied: torch>=2.2 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (2.7.1+computecanada)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in ./env_hf/lib/python3.12/site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env_hf/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env_hf/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0+computecanada)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./env_hf/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.1.10+computecanada)\n",
      "Requirement already satisfied: psutil in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/ipykernel/2024a/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.8)\n",
      "Requirement already satisfied: setuptools in ./env_hf/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (80.9.0+computecanada)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./env_hf/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (1.14.0+computecanada)\n",
      "Requirement already satisfied: networkx in ./env_hf/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (3.6)\n",
      "Requirement already satisfied: jinja2 in ./env_hf/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (3.1.6+computecanada)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0+computecanada)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env_hf/lib/python3.12/site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.2+computecanada)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env_hf/lib/python3.12/site-packages (from requests->transformers[torch]) (3.4.4+computecanada)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env_hf/lib/python3.12/site-packages (from requests->transformers[torch]) (3.11+computecanada)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env_hf/lib/python3.12/site-packages (from requests->transformers[torch]) (2.5.0+computecanada)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env_hf/lib/python3.12/site-packages (from requests->transformers[torch]) (2025.11.12)\n"
     ]
    }
   ],
   "source": [
    "#Download required imports\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch\n",
    "!{sys.executable} -m pip install torchcodec\n",
    "!{sys.executable} -m pip install evaluate\n",
    "!{sys.executable} -m pip install jiwer\n",
    "!{sys.executable} -m pip install transformers[torch]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "914a7e39-b54b-4fa2-bd7f-2036ad564390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulaval.ca/lemun9/env_hf/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text', 'audio_filepath', '__index_level_0__'],\n",
      "        num_rows: 5389\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text', 'audio_filepath', '__index_level_0__'],\n",
      "        num_rows: 1348\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#Import dataset and split\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "common_voice = DatasetDict()\n",
    "\n",
    "common_voice[\"train\"] = load_dataset(\"rishabbahal/quebecois_canadian_french_dataset\", \"default\", split=\"train\")\n",
    "common_voice[\"test\"] = load_dataset(\"rishabbahal/quebecois_canadian_french_dataset\", \"default\", split=\"test\")\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14bd99b6-e3c5-47aa-88c5-d67994120352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 5389\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'text'],\n",
      "        num_rows: 1348\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "#Keep only needed data (audio and text)\n",
    "common_voice = common_voice.remove_columns([\"audio_filepath\", \"__index_level_0__\"])\n",
    "\n",
    "print(common_voice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "122ec3bc-dc4f-467c-98aa-1d15b12fddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load feature extractor from pre-trained check-point\n",
    "from transformers import WhisperFeatureExtractor\n",
    "\n",
    "feature_extractor = WhisperFeatureExtractor.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b0d2943-9973-438c-b78a-f20b5d38aa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load tokenizer\n",
    "from transformers import WhisperTokenizer\n",
    "\n",
    "tokenizer = WhisperTokenizer.from_pretrained(\"openai/whisper-small\", language=\"French\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "420b4884-4464-4eb7-b047-da254252d1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine feature extractor and tokenizer to create the processor\n",
    "from transformers import WhisperProcessor\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\", language=\"French\", task=\"transcribe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65f5dd0a-c8e9-4b83-bb98-3c4f690bdc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio array shape: torch.Size([36784])\n",
      "Sampling rate: 16000\n"
     ]
    }
   ],
   "source": [
    "#Prepare data\n",
    "sample = common_voice[\"train\"][2]\n",
    "audio_decoder = sample['audio']\n",
    "audio_samples = audio_decoder.get_all_samples()\n",
    "\n",
    "audio_array = audio_samples.data.squeeze()\n",
    "sampling_rate = audio_samples.sample_rate\n",
    "\n",
    "print(f\"Audio array shape: {audio_array.shape}\")\n",
    "print(f\"Sampling rate: {sampling_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aececaee-e16d-4b67-968b-d1a97ebfdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare dataset\n",
    "def prepare_dataset(batch):\n",
    "    # load and resample audio data from 48 to 16kHz\n",
    "    audio = batch[\"audio\"]\n",
    "    audio_samples = audio.get_all_samples()\n",
    "    audio_array = audio_samples.data.squeeze(0).numpy()\n",
    "\n",
    "    # compute log-Mel input features from input audio array\n",
    "    batch[\"input_features\"] = feature_extractor(audio_array, sampling_rate=16000).input_features[0]\n",
    "\n",
    "    # encode target text to label ids\n",
    "    batch[\"labels\"] = tokenizer(batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a78d5f0-d3fb-4670-94f4-38d7533bae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map (num_proc=1): 100%|██████████| 5389/5389 [01:26<00:00, 62.14 examples/s]\n",
      "Map (num_proc=1): 100%|██████████| 1348/1348 [00:22<00:00, 61.07 examples/s]\n"
     ]
    }
   ],
   "source": [
    "#Apply data preparation function to training examples\n",
    "common_voice = common_voice.map(prepare_dataset, remove_columns=common_voice.column_names[\"train\"], num_proc=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bef0130-f4c5-4b7a-9dcc-d267c8ec8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pre-trained checkpoint\n",
    "from transformers import WhisperForConditionalGeneration\n",
    "\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8db9345-9824-4d6d-aa0f-3ccaa6b335f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Disable automatic language detection and force model to generate french\n",
    "model.generation_config.language = \"french\"\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "model.generation_config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a2f442d-13d8-4f76-aa50-939fac1cdd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define data collector\n",
    "import torch\n",
    "\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorSpeechSeq2SeqWithPadding:\n",
    "    processor: Any\n",
    "    decoder_start_token_id: int\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
    "        # split inputs and labels since they have to be of different lengths and need different padding methods\n",
    "        # first treat the audio inputs by simply returning torch tensors\n",
    "        input_features = [{\"input_features\": feature[\"input_features\"]} for feature in features]\n",
    "        batch = self.processor.feature_extractor.pad(input_features, return_tensors=\"pt\")\n",
    "\n",
    "        # get the tokenized label sequences\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "        # pad the labels to max length\n",
    "        labels_batch = self.processor.tokenizer.pad(label_features, return_tensors=\"pt\")\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        # if bos token is appended in previous tokenization step,\n",
    "        # cut bos token here as it's append later anyways\n",
    "        if (labels[:, 0] == self.decoder_start_token_id).all().cpu().item():\n",
    "            labels = labels[:, 1:]\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98f65cf5-5387-45fa-a545-49d857e79291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize data collector\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(\n",
    "    processor=processor,\n",
    "    decoder_start_token_id=model.config.decoder_start_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "257b2fe1-9a5a-4d78-a895-7223f739b407",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose evaluation metrics (error rate)\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2cab28b-5da7-45a5-a9fb-340566f1acd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function that takes the model's predictions and returns the evaluation metric\n",
    "def compute_metrics(pred):\n",
    "    pred_ids = pred.predictions\n",
    "    label_ids = pred.label_ids\n",
    "\n",
    "    # replace -100 with the pad_token_id\n",
    "    label_ids[label_ids == -100] = tokenizer.pad_token_id\n",
    "\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    pred_str = tokenizer.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    label_str = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "\n",
    "    wer = 100 * metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee0f0451-e7d7-46bf-aebe-6f0562a0694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "ckpt_dir = \"/scratch/lemun9@ulaval.ca/whisper_checkpoints\"\n",
    "\n",
    "if os.path.exists(ckpt_dir):\n",
    "    shutil.rmtree(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6593a9cd-3305-4c24-9abb-5d654fc27c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define training configuration\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir = \"/scratch/lemun9@ulaval.ca/whisper_checkpoints\",\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=8,  # increase by 2x for every 2x decrease in batch size\n",
    "    learning_rate=1e-5,\n",
    "    warmup_steps=500,\n",
    "    max_steps=4000,\n",
    "    eval_strategy=\"steps\", \n",
    "    save_strategy=\"steps\", \n",
    "    save_steps=1000,\n",
    "    eval_steps=200, \n",
    "    gradient_checkpointing=False,\n",
    "    fp16=False,\n",
    "    per_device_eval_batch_size=1,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    logging_steps=25,\n",
    "    report_to=[],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    "    save_only_model=True,\n",
    "    save_total_limit=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "289a0265-c97d-43d2-9b1f-5a3f0208ecdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "#Forward training agruments, model, dataset, data collector, and compute metrics function to HuggingFace trainer\n",
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=model,\n",
    "    train_dataset=common_voice[\"train\"],\n",
    "    eval_dataset=common_voice[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4655ac97-5091-485a-8b70-980320cecf6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save processor object\n",
    "processor.save_pretrained(training_args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "199ae868-f059-49c8-8dfc-a5376d554a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make space for the model training\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e2fa0b-de88-49b3-aad3-a6a1f25f294c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='601' max='4000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 601/4000 1:01:11 < 5:47:12, 0.16 it/s, Epoch 0.89/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.194700</td>\n",
       "      <td>1.128721</td>\n",
       "      <td>55.590855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.015500</td>\n",
       "      <td>0.971471</td>\n",
       "      <td>54.337096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='859' max='1348' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 859/1348 06:59 < 03:59, 2.04 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "#Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f48fa1-97b4-4947-9989-b410ba0e1013",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_hf)",
   "language": "python",
   "name": "env_hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
