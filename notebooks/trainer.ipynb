{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f196e01f4567198",
   "metadata": {},
   "source": [
    "# Model PEFT training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7db3c0c-1584-4f8f-a30f-a35b2d2482ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: evaluate in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (0.4.6)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (4.4.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from evaluate) (1.26.4+computecanada)\n",
      "Requirement already satisfied: dill in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (0.4.0+computecanada)\n",
      "Requirement already satisfied: pandas in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from evaluate) (2.2.1+computecanada)\n",
      "Requirement already satisfied: requests>=2.19.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (2.32.5+computecanada)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (4.67.1+computecanada)\n",
      "Requirement already satisfied: xxhash in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (3.5.0+computecanada)\n",
      "Requirement already satisfied: multiprocess in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (0.70.18+computecanada)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from evaluate) (0.36.0)\n",
      "Requirement already satisfied: packaging in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from evaluate) (24.1+computecanada)\n",
      "Requirement already satisfied: filelock in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.12.4/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (3.13.4)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyarrow-9999+dummy.computecanada-py3-none-any.whl (from datasets>=2.0.0->evaluate)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (0.28.1+computecanada)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from datasets>=2.0.0->evaluate) (6.0.2+computecanada)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15+computecanada)\n",
      "Requirement already satisfied: anyio in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (4.12.0)\n",
      "Requirement already satisfied: certifi in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (1.0.9+computecanada)\n",
      "Requirement already satisfied: idna in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from httpx<1.0.0->datasets>=2.0.0->evaluate) (3.11+computecanada)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=2.0.0->evaluate) (0.16.0+computecanada)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.12.4/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.10+computecanada)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1+computecanada)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0+computecanada)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.4.0+computecanada)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.8.0+computecanada)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.7.0+computecanada)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.4.1+computecanada)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.22.0+computecanada)\n",
      "Processing /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic/pyarrow_noinstall-9999+dummy.computecanada.tar.gz (from pyarrow>=21.0.0->datasets>=2.0.0->evaluate)\n",
      "  Installing build dependencies ... \u001B[?25ldone\n",
      "\u001B[?25h  Getting requirements to build wheel ... \u001B[?25lerror\n",
      "  \u001B[1;31merror\u001B[0m: \u001B[1msubprocess-exited-with-error\u001B[0m\n",
      "  \n",
      "  \u001B[31m×\u001B[0m \u001B[32mGetting requirements to build wheel\u001B[0m did not run successfully.\n",
      "  \u001B[31m│\u001B[0m exit code: \u001B[1;36m1\u001B[0m\n",
      "  \u001B[31m╰─>\u001B[0m \u001B[31m[19 lines of output]\u001B[0m\n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m         \u001B[92mThis is a normal error generated by this dummy wheel.\u001B[0m\n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m         PyArrow is available from the Arrow module, please see https://docs.alliancecan.ca/wiki/Arrow\n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m         \u001B[1m\u001B[93mIMPORTANT\u001B[0m: the module \u001B[1mmust\u001B[0m be loaded \u001B[1mbefore\u001B[0m activating your virtual environment.\n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m         1. Deactivate your virtual environment : deactivate\n",
      "  \u001B[31m   \u001B[0m         2. Load the Arrow module : module load gcc arrow/x.y.z\n",
      "  \u001B[31m   \u001B[0m         3. Activate your virtual env. : source <env>/bin/activate\n",
      "  \u001B[31m   \u001B[0m         4. And re-run your pip install command.\n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \n",
      "  \u001B[31m   \u001B[0m \u001B[31m[end of output]\u001B[0m\n",
      "  \n",
      "  \u001B[1;35mnote\u001B[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001B[31mERROR: Failed to build 'pyarrow-noinstall' when getting requirements to build wheel\u001B[0m\u001B[31m\n",
      "\u001B[0m\u001B[?25hDefaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: jiwer in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (4.0.0)\n",
      "Requirement already satisfied: click>=8.1.8 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from jiwer) (8.3.1)\n",
      "Requirement already satisfied: rapidfuzz>=3.9.7 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from jiwer) (3.13.0+computecanada)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: IProgress in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (0.4+computecanada)\n",
      "Requirement already satisfied: six in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from IProgress) (1.16.0+computecanada)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in links: /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/x86-64-v3, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/gentoo2023/generic, /cvmfs/soft.computecanada.ca/custom/python/wheelhouse/generic\n",
      "Requirement already satisfied: bitsandbytes in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (0.49.0+computecanada)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from bitsandbytes) (2.7.1+computecanada)\n",
      "Requirement already satisfied: numpy>=1.17 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from bitsandbytes) (1.26.4+computecanada)\n",
      "Requirement already satisfied: packaging>=20.9 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from bitsandbytes) (24.1+computecanada)\n",
      "Requirement already satisfied: filelock in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.12.4/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.12.4/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (4.12.1)\n",
      "Requirement already satisfied: setuptools in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/python/3.12.4/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (70.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0+computecanada)\n",
      "Requirement already satisfied: networkx in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.5+computecanada)\n",
      "Requirement already satisfied: jinja2 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6+computecanada)\n",
      "Requirement already satisfied: fsspec in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (2025.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /cvmfs/soft.computecanada.ca/easybuild/software/2023/x86-64-v3/Compiler/gcccore/scipy-stack/2024a/lib/python3.12/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0+computecanada)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2+computecanada)\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate\n",
    "!pip install jiwer\n",
    "!pip install IProgress\n",
    "!pip install bitsandbytes\n",
    "\n",
    "# !pip install transformers[torch]\n",
    "# !pip install soundfile\n",
    "# !pip install torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b011499-1c0b-4af8-8a69-658784233451",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ceca9b-1703-418b-9ab5-d4ede1bed9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ulaval.ca/mapod13/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from modules.data import load_common_voice_data\n",
    "\n",
    "data = load_common_voice_data()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9a31b372e8ab0",
   "metadata": {},
   "source": [
    "## Create LoRA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "573013e3f6fe631b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T19:59:24.548052Z",
     "start_time": "2025-12-20T19:59:19.583993Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,594,240 || all params: 245,329,152 || trainable%: 1.4651\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from config.variables import TOKENIZER_LANGUAGE, MODEL_VERSION, MODEL_LANGUAGE\n",
    "from modules.model import get_model, get_tokenizer\n",
    "\n",
    "model = get_model()\n",
    "tokenizer = get_tokenizer()\n",
    "\n",
    "model.generation_config.language = MODEL_LANGUAGE\n",
    "model.generation_config.task = \"transcribe\"\n",
    "\n",
    "#Freeze Whisper weights\n",
    "model.requires_grad_(False)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "peft_config = LoraConfig(r=32,\n",
    "                         lora_alpha=64,\n",
    "                         target_modules=['q_proj', 'v_proj'],\n",
    "                         bias='none',\n",
    "                         use_dora=True)\n",
    "\n",
    "lora_model = get_peft_model(model, peft_config)\n",
    "lora_model.config.use_cache = False\n",
    "lora_model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b93f138f78cd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-20T19:25:18.299271Z",
     "start_time": "2025-12-20T19:25:18.287370Z"
    }
   },
   "source": [
    "## Setup trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4d2005bcf1f3e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.trainer_seq2seq.Seq2SeqTrainer object at 0x7f66d658c0b0>\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from modules.training import compute_metrics, DataCollatorSpeechSeq2SeqWithPadding\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from modules.model import get_processor\n",
    "\n",
    "processor = get_processor()\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,  # increase by 2x for every 2x decrease in batch size\n",
    "    gradient_checkpointing=False,\n",
    "    learning_rate=1e-5,\n",
    "    max_steps=7000,\n",
    "    warmup_steps=500,\n",
    "    save_strategy='best',  #Keep only best model when saving\n",
    "    save_steps=500,\n",
    "    save_only_model=True,\n",
    "    save_total_limit=2,\n",
    "    # eval_strategy=\"no\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    fp16=True,\n",
    "    per_device_eval_batch_size=1,\n",
    "    predict_with_generate=True,\n",
    "    generation_max_length=225,\n",
    "    logging_steps=100,\n",
    "    report_to=[],\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"wer\",\n",
    "    greater_is_better=False,\n",
    "    push_to_hub=False,\n",
    "    optim=\"adamw_torch\"\n",
    ")\n",
    "data_collator = DataCollatorSpeechSeq2SeqWithPadding(processor=processor,\n",
    "                                                     decoder_start_token_id=model.config.decoder_start_token_id)\n",
    "\n",
    "data['test'].take(1000)\n",
    "trainer = Seq2SeqTrainer(\n",
    "    args=training_args,\n",
    "    model=lora_model,\n",
    "    train_dataset=data[\"train\"],\n",
    "    eval_dataset=data['test'],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa577758a6aa953",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8da51364f70be981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a WhisperTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7000' max='7000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7000/7000 9:42:48, Epoch 7/9223372036854775807]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.140100</td>\n",
       "      <td>1.853100</td>\n",
       "      <td>87.260250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.348200</td>\n",
       "      <td>1.295434</td>\n",
       "      <td>69.675641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.172000</td>\n",
       "      <td>1.124788</td>\n",
       "      <td>61.129685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.063500</td>\n",
       "      <td>1.030790</td>\n",
       "      <td>58.243885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.013200</td>\n",
       "      <td>0.975130</td>\n",
       "      <td>55.205584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.927100</td>\n",
       "      <td>0.936408</td>\n",
       "      <td>53.281717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.914100</td>\n",
       "      <td>0.909710</td>\n",
       "      <td>51.481025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.848300</td>\n",
       "      <td>0.889016</td>\n",
       "      <td>50.853422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.831800</td>\n",
       "      <td>0.873036</td>\n",
       "      <td>49.920816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.818700</td>\n",
       "      <td>0.862203</td>\n",
       "      <td>49.117250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.867500</td>\n",
       "      <td>0.851656</td>\n",
       "      <td>48.718400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.840600</td>\n",
       "      <td>0.845814</td>\n",
       "      <td>48.571764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.785800</td>\n",
       "      <td>0.842349</td>\n",
       "      <td>48.571764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.820600</td>\n",
       "      <td>0.841013</td>\n",
       "      <td>48.384069</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7000, training_loss=1.1183025665283204, metrics={'train_runtime': 34971.2198, 'train_samples_per_second': 1.601, 'train_steps_per_second': 0.2, 'total_flos': 1.645062193152e+19, 'train_loss': 1.1183025665283204, 'epoch': 7.114})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#Create new directory for checkpoints with the training specs\n",
    "output_dir = Path(\n",
    "    f'cps/cp_{MODEL_VERSION.replace('/', '-')}-{MODEL_LANGUAGE}_T{TOKENIZER_LANGUAGE}_{datetime.now().strftime(\"%d-%m-%Y_%H:%M\")}')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "trainer.args.output_dir = output_dir\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51e5cc-6437-4fb1-9916-4017ace34728",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3efd2d-9385-43a5-9b44-94a032e55547",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jiwer import wer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def compute_dataset_wer(model, processor, dataset):\n",
    "    preds = []\n",
    "    refs = []\n",
    "    for item in tqdm(dataset, desc=\"Processing\"):\n",
    "        audio = item[\"audio\"][\"array\"]\n",
    "        text = item[\"text\"]\n",
    "        inputs = processor(audio, sampling_rate=16000, return_tensors=\"pt\")\n",
    "        with torch.no_grad():\n",
    "            ids = model.generate(inputs[\"input_features\"].to(\"cuda\"), max_length=225)\n",
    "        pred = processor.tokenizer.batch_decode(ids, skip_special_tokens=True)[0]\n",
    "        preds.append(pred)\n",
    "        refs.append(text)\n",
    "    return wer(refs, preds)\n",
    "\n",
    "\n",
    "common_voice_test = load_common_voice_data()[\"test\"]\n",
    "\n",
    "print(\"Evaluating fine-tuned model...\")\n",
    "wer_finetuned = compute_dataset_wer(lora_model, processor, common_voice_test)\n",
    "\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(\"RESULTS\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"WER fine-tuned: {wer_finetuned * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9716a9d-b1bb-4ff3-9b6f-01eae7ab20cb",
   "metadata": {},
   "source": [
    "## Try example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c617190a-e7be-4b1e-ba4e-65e57d9de0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference text : Il est directeur de l'Observatoire astronomique de Majorque.\n",
      "Fine-tuned : Il était éteint de l'observatoire astronomique de Majork.\n",
      "WER fine tuned: 0.5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from modules.data import load_common_voice_raw\n",
    "from modules.model import get_model\n",
    "\n",
    "\n",
    "def transcribe_from_audio_with(model, processor, audio_array):\n",
    "    inputs = processor(audio_array, sampling_rate=16000, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ids = model.generate(inputs[\"input_features\"], max_length=225)\n",
    "\n",
    "    txt = processor.tokenizer.batch_decode(ids, skip_special_tokens=True)[0]\n",
    "    return txt\n",
    "\n",
    "\n",
    "sample = load_common_voice_raw()[\"test\"][119]\n",
    "audio = sample[\"audio\"][\"array\"]\n",
    "sr = sample[\"audio\"][\"sampling_rate\"]\n",
    "expected_text = sample[\"text\"]\n",
    "print(\"Reference text :\", expected_text)\n",
    "model = get_model()\n",
    "\n",
    "lora_model = PeftModel.from_pretrained(model,\n",
    "                                       './cps/cp_openai-whisper-small-french_TFrench_21-12-2025_23:25/checkpoint-7000')\n",
    "txt_ft = transcribe_from_audio_with(lora_model, processor, audio)\n",
    "\n",
    "print(\"Fine-tuned :\", txt_ft)\n",
    "\n",
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"wer\")\n",
    "\n",
    "wer_ft = metric.compute(predictions=[txt_ft], references=[expected_text])\n",
    "\n",
    "print(\"WER fine tuned:\", wer_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3f71e2-be85-4272-9c6b-53a24b32a3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env_hf)",
   "language": "python",
   "name": "env_hf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
